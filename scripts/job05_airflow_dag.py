from dateutil import parser
from datetime import datetime, timedelta, date
from datetime import timezone
from airflow import DAG
from airflow.operators.dummy_operator import DummyOperator
from cloudera.cdp.airflow.operators.cde_operator import CDEJobRunOperator


owner = "userxx"

DAG_name = owner + "_Airflow_Dag"
job_name_1 = owner + "_job02"
job_name_2 = owner + "_job03"
job_name_3 = owner + "_job04"

default_args = {
    'owner': owner,
    'retry_delay': timedelta(seconds=5),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 0
}


dag = DAG(
    DAG_name,
    default_args=default_args,
    start_date=datetime.now()-timedelta(1),
    end_date=datetime.now()+timedelta(1),
    schedule_interval='*/20 * * * *',
    catchup=False,
    is_paused_upon_creation=False
)


start = DummyOperator(task_id='start', dag=dag)

Texas_Small = CDEJobRunOperator(
    task_id=job_name_1,
    retries=3,
    dag=dag,
    job_name=job_name_1
)

Texas_Over150k = CDEJobRunOperator(
    task_id=job_name_2,
    dag=dag,
    job_name=job_name_2
)

Final_Report = CDEJobRunOperator(
    task_id=job_name_3,
    dag=dag,
    job_name=job_name_3
)

end = DummyOperator(task_id='end', dag=dag)

start >> Texas_Small >> Texas_Over150k >> Final_Report >> end
